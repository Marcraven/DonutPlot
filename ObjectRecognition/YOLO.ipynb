{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "# Functions to generate simple plots\n",
        "\n",
        "\n",
        "def create_scatterplot_with_coco_bounding_boxes(num_points=10, size=(256, 256), dot_size=3):\n",
        "    # Initialize an image with ones (white)\n",
        "    image = np.ones((size[0], size[1], 3), dtype=np.uint8) * 255\n",
        "\n",
        "    # Generate random points\n",
        "    points = np.random.randint(0, size[0], size=(num_points, 2))\n",
        "\n",
        "    # Bounding boxes list\n",
        "    bounding_boxes = []\n",
        "\n",
        "    # Drawing points on the image and creating bounding boxes\n",
        "    for point in points:\n",
        "        x, y = point\n",
        "        # Draw a bigger dot\n",
        "        image[y-dot_size:y+dot_size+1, x-dot_size:x+dot_size+1] = [0, 0, 0]  # Black point\n",
        "\n",
        "        # Bounding box for each point (in COCO format)\n",
        "        bb_width = bb_height = 2 * dot_size\n",
        "        x_center = x / size[0]\n",
        "        y_center = y / size[1]\n",
        "        width_normalized = bb_width / size[0]\n",
        "        height_normalized = bb_height / size[1]\n",
        "\n",
        "        bounding_box = (x_center, y_center, width_normalized, height_normalized)\n",
        "        bounding_boxes.append(bounding_box)\n",
        "\n",
        "    return image, bounding_boxes\n",
        "\n",
        "def save_coco_bounding_boxes_to_txt(bounding_boxes, filename):\n",
        "    with open(filename, 'w') as file:\n",
        "        for box in bounding_boxes:\n",
        "            x_center, y_center, width, height = box\n",
        "            x1 = x_center - width / 2\n",
        "            y1 = y_center - height / 2\n",
        "            x2 = x_center + width / 2\n",
        "            y2 = y_center + height / 2\n",
        "            file.write(f'0 {x1} {y1} {width} {height}\\n')\n",
        "\n",
        "def read_coco_bounding_boxes_from_txt(filename):\n",
        "    bounding_boxes = []\n",
        "    with open(filename, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            data = line.strip().split()\n",
        "            category_id = int(data[0])\n",
        "            x1, y1, width, height = map(float, data[1:])\n",
        "            x_center = x1 + width / 2\n",
        "            y_center = y1 + height / 2\n",
        "            bounding_box = (x_center, y_center, width, height)\n",
        "            bounding_boxes.append(bounding_box)\n",
        "    return bounding_boxes\n",
        "\n",
        "def visualize_coco_bounding_boxes(image, bounding_boxes, size=(256, 256)):\n",
        "    # Iterate over the bounding boxes and draw them\n",
        "    for box in bounding_boxes:\n",
        "        x_center, y_center, width, height = box\n",
        "        x_center *= size[0]\n",
        "        y_center *= size[1]\n",
        "        width *= size[0]\n",
        "        height *= size[1]\n",
        "\n",
        "        # Convert COCO format to top-left and bottom-right coordinates\n",
        "        x1 = int(x_center - width / 2)\n",
        "        y1 = int(y_center - height / 2)\n",
        "        x2 = int(x_center + width / 2)\n",
        "        y2 = int(y_center + height / 2)\n",
        "\n",
        "        # Draw rectangle (bounding box)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 1)  # Red box\n",
        "\n",
        "    return image\n",
        "\n",
        "# Generate image and bounding boxes\n",
        "scatter_image, coco_boxes = create_scatterplot_with_coco_bounding_boxes()\n",
        "\n",
        "# # Save the generated image\n",
        "# image_path = 'scatterplot.png'\n",
        "# cv2.imwrite(image_path, scatter_image)\n",
        "\n",
        "# # Save the bounding boxes to a text file in COCO format\n",
        "# bounding_boxes_path = 'bounding_boxes.txt'\n",
        "# save_coco_bounding_boxes_to_txt(coco_boxes, bounding_boxes_path)\n",
        "\n",
        "# # Read the image and bounding box information from the files\n",
        "# loaded_image = cv2.imread(image_path)\n",
        "# loaded_coco_boxes = read_coco_bounding_boxes_from_txt(bounding_boxes_path)\n",
        "\n",
        "# # Visualize the bounding boxes on the loaded image\n",
        "# visualized_image = visualize_coco_bounding_boxes(loaded_image.copy(), loaded_coco_boxes)\n",
        "\n",
        "# # Display or save the visualized image\n",
        "# visualized_image_path = 'visualized_coco_scatterplot.png'\n",
        "# cv2.imwrite(visualized_image_path, visualized_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create folders to fill in with data\n",
        "import os\n",
        "base_dir='yolo'\n",
        "dirs =  ['train', 'test', 'val']\n",
        "for subset in dirs:\n",
        "    img_dir = os.path.join(base_dir, 'images', subset)\n",
        "    label_dir = os.path.join(base_dir, 'labels', subset)\n",
        "    os.makedirs(img_dir, exist_ok=True)\n",
        "    os.makedirs(label_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "# Train the model with Ultralytics - wrap around of Pytorch Yolo model\n",
        "# yolov8s-p2 - version for detecting smaller objects on images\n",
        "# https://github.com/ultralytics/ultralytics/issues/981  - you can find out more here\n",
        "def train_model():\n",
        "    # Load the pre-trained model\n",
        "    model = YOLO(\"yolov8s-p2.yaml\").load(\"yolov8s.pt\")\n",
        "\n",
        "    # Train the model\n",
        "    model.train(\n",
        "        data=\"dataset.yaml\", epochs=200,  imgsz=320, save=True, format='onnx'\n",
        "    )  # Set imgsz to 320 for training on 320xsomething images\n",
        "\n",
        "    # Export the model to ONNX format\n",
        "    path = model.export()\n",
        "    print(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# I WOULD HIGHLY RECCOMEND TRAINING USING COMET (its like MLFLOW)\n",
        "# https://docs.ultralytics.com/modes/train/#logging - HOW TO\n",
        "# you will have all the weights and training progress save there inside of experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'best-30.pt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/marcraven/code/Marcraven/DonutPlot/ObjectRecognition/Train simple YOLO model to detect scatter points.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marcraven/code/Marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Example of predictions\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marcraven/code/Marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39multralytics\u001b[39;00m \u001b[39mimport\u001b[39;00m YOLO\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marcraven/code/Marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m YOLO(\u001b[39m'\u001b[39;49m\u001b[39mbest-30.pt\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# Load this from\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/marcraven/code/Marcraven/DonutPlot/ObjectRecognition/Train%20simple%20YOLO%20model%20to%20detect%20scatter%20points.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m results \u001b[39m=\u001b[39m model(\u001b[39m'\u001b[39m\u001b[39mObjectRecognition/yolo/dataset/test/0000.jpg\u001b[39m\u001b[39m'\u001b[39m, imgsz\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, save\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, conf\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/engine/model.py:94\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, task)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(model, task)\n\u001b[1;32m     93\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load(model, task)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/engine/model.py:146\u001b[0m, in \u001b[0;36mModel._load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    144\u001b[0m suffix \u001b[39m=\u001b[39m Path(weights)\u001b[39m.\u001b[39msuffix\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m suffix \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt \u001b[39m=\u001b[39m attempt_load_one_weight(weights)\n\u001b[1;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39margs[\u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverrides \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset_ckpt_args(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39margs)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/nn/tasks.py:628\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mattempt_load_one_weight\u001b[39m(weight, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fuse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    627\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m     ckpt, weight \u001b[39m=\u001b[39m torch_safe_load(weight)  \u001b[39m# load ckpt\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     args \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mDEFAULT_CFG_DICT, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(ckpt\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtrain_args\u001b[39m\u001b[39m'\u001b[39m, {}))}  \u001b[39m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     model \u001b[39m=\u001b[39m (ckpt\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mema\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m ckpt[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mfloat()  \u001b[39m# FP32 model\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/ultralytics/nn/tasks.py:567\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[39mwith\u001b[39;00m temporary_modules({\n\u001b[1;32m    564\u001b[0m             \u001b[39m'\u001b[39m\u001b[39multralytics.yolo.utils\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39multralytics.utils\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    565\u001b[0m             \u001b[39m'\u001b[39m\u001b[39multralytics.yolo.v8\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39multralytics.models.yolo\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    566\u001b[0m             \u001b[39m'\u001b[39m\u001b[39multralytics.yolo.data\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39multralytics.data\u001b[39m\u001b[39m'\u001b[39m}):  \u001b[39m# for legacy 8.0 Classify and Pose models\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(file, map_location\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m), file  \u001b[39m# load\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# e.name is missing module name\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m'\u001b[39m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    436\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/DonutPlot/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best-30.pt'"
          ]
        }
      ],
      "source": [
        "# Example of predictions\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('best-30.pt') # Load this from\n",
        "results = model('ObjectRecognition/yolo/dataset/test/0000.jpg', imgsz=256, save=True, conf=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "lewagon",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
